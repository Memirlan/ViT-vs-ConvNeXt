# In progress...
ViT base 16 and ConvNeXt models are of different architectures types, yet their model and parameter sizes are very similar (~330 MB). Also, ConvNeXt was designed as a CNN model that achieves a transformer level performance.
Here, I want to use pretrained versions of both models and try fine-tuning them on a small classification dataset and compare their performance. ViT prefer a large dataset with a lower learning rate training, so it might show a slightly poor performance in comparison.
