{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8780816,"sourceType":"datasetVersion","datasetId":3442424}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchvision\n\n!python -V; printf '\\n'\n!nvcc -V; printf '\\n'\nprint(f'CUDA is available: {torch.cuda.is_available()}')\nprint(f'Current device: {torch.cuda.current_device()}')\nprint(f'Device name: {torch.cuda.get_device_name(0)}')\nprint(f'CUDNN version: {torch.backends.cudnn.version()}')\nprint(f'CUDNN enabled: {torch.backends.cudnn.enabled}')\nprint(f'CUDA version by torch: {torch.version.cuda}')\nprint(f'Torchvision version: {torchvision.__version__}')\nprint(f'Torchvision loc: {torchvision.__file__}')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:48:48.597547Z","iopub.execute_input":"2025-05-04T11:48:48.597854Z","iopub.status.idle":"2025-05-04T11:48:48.918248Z","shell.execute_reply.started":"2025-05-04T11:48:48.597832Z","shell.execute_reply":"2025-05-04T11:48:48.917329Z"}},"outputs":[{"name":"stdout","text":"Python 3.11.11\n\nnvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2024 NVIDIA Corporation\nBuilt on Thu_Jun__6_02:18:23_PDT_2024\nCuda compilation tools, release 12.5, V12.5.82\nBuild cuda_12.5.r12.5/compiler.34385749_0\n\nCUDA is available: True\nCurrent device: 0\nDevice name: Tesla T4\nCUDNN version: 90300\nCUDNN enabled: True\nCUDA version by torch: 12.4\nTorchvision version: 0.20.1+cu124\nTorchvision loc: /usr/local/lib/python3.11/dist-packages/torchvision/__init__.py\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import torchvision.models\n\nmodel = torchvision.models.vit_b_16(pretrained=True)\n\nnum_classes = 75\nmodel.heads.head = torch.nn.Linear(model.heads.head.in_features, num_classes)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:04:23.993477Z","iopub.execute_input":"2025-05-04T11:04:23.994274Z","iopub.status.idle":"2025-05-04T11:04:27.418602Z","shell.execute_reply.started":"2025-05-04T11:04:23.994243Z","shell.execute_reply":"2025-05-04T11:04:27.418027Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to /root/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth\n100%|██████████| 330M/330M [00:01<00:00, 203MB/s] \n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom PIL import Image\nimport pandas as pd\nimport os\nfrom torch.utils.data import random_split\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\n\nclass ButterflyDataset(Dataset):\n    def __init__(self, csv_file, root_dir, transform=None):\n        self.annotations = pd.read_csv(csv_file)\n        self.root_dir = root_dir\n        self.transform = transform\n        self.label_to_idx = {label: idx for idx, label in enumerate(self.annotations['label'].unique())}\n\n    def __len__(self):\n        return len(self.annotations)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.root_dir, self.annotations.iloc[idx, 0])\n        image = Image.open(img_path).convert(\"RGB\")\n        label_str = self.annotations.iloc[idx, 1]\n        label = self.label_to_idx[label_str]\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=(0.5,), std=(0.5,))  # Adjust channels as needed\n])\n\nthe_dataset = ButterflyDataset(\n    csv_file='/kaggle/input/butterfly-image-classification/Training_set.csv',\n    root_dir='/kaggle/input/butterfly-image-classification/train',\n    transform=transform\n)\n\ntrain_size = int(0.8 * len(the_dataset))\nval_size = len(the_dataset) - train_size\n\ntrain_dataset, val_dataset = random_split(the_dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:06:54.842736Z","iopub.execute_input":"2025-05-04T11:06:54.843028Z","iopub.status.idle":"2025-05-04T11:06:54.860189Z","shell.execute_reply.started":"2025-05-04T11:06:54.843004Z","shell.execute_reply":"2025-05-04T11:06:54.859601Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.optim as optim\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=3e-5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:07:05.937271Z","iopub.execute_input":"2025-05-04T11:07:05.937540Z","iopub.status.idle":"2025-05-04T11:07:06.257120Z","shell.execute_reply.started":"2025-05-04T11:07:05.937520Z","shell.execute_reply":"2025-05-04T11:07:06.256520Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import time\nfrom tqdm import tqdm\n\nhistory = {\n    'train_loss': [],\n    'train_acc1': [],\n    'train_acc5': [],\n    'val_loss': [],\n    'val_acc1': [],\n    'val_acc5': []\n}\n\ndef evaluate(model, dataloader, device):\n    model.eval()\n    correct_top1 = 0\n    correct_top5 = 0\n    total = 0\n    running_loss = 0.0\n\n    with torch.no_grad():\n        for images, labels in tqdm(dataloader, desc=\"Validating\", leave=False):\n            images, labels = images.to(device), labels.to(device)\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            running_loss += loss.item()\n\n            _, preds = outputs.topk(5, dim=1)\n            correct = preds.eq(labels.view(-1, 1))\n\n            correct_top1 += correct[:, 0].sum().item()\n            correct_top5 += correct.any(dim=1).sum().item()\n            total += labels.size(0)\n\n    avg_loss = running_loss / len(dataloader)\n    acc1 = correct_top1 / total\n    acc5 = correct_top5 / total\n\n    return avg_loss, acc1, acc5\n\nnum_epochs = 10","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:07:27.514018Z","iopub.execute_input":"2025-05-04T11:07:27.514295Z","iopub.status.idle":"2025-05-04T11:07:27.520601Z","shell.execute_reply.started":"2025-05-04T11:07:27.514275Z","shell.execute_reply":"2025-05-04T11:07:27.519935Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"from IPython.display import clear_output, display\nimport matplotlib.pyplot as plt\nfrom IPython.display import display as ipy_display\nimport ipywidgets as widgets\n\nplot_output = widgets.Output()\nipy_display(plot_output)\n\ndef plot_history(history):\n    with plot_output:\n        clear_output(wait=True)\n        epochs = range(1, len(history['train_loss']) + 1)\n\n        plt.figure(figsize=(18, 5))\n\n        # 1. Loss\n        plt.subplot(1, 3, 1)\n        plt.plot(epochs, history['train_loss'], label='Train Loss')\n        plt.plot(epochs, history['val_loss'], label='Val Loss')\n        plt.xlabel('Epoch')\n        plt.ylabel('Loss')\n        plt.title('Train vs Val Loss')\n        plt.legend()\n\n        # 2. ACC@1\n        plt.subplot(1, 3, 2)\n        plt.plot(epochs, history['train_acc1'], label='Train ACC@1')\n        plt.plot(epochs, history['val_acc1'], label='Val ACC@1')\n        plt.xlabel('Epoch')\n        plt.ylabel('Accuracy')\n        plt.title('Train vs Val ACC@1')\n        plt.legend()\n\n        # 3. ACC@5\n        plt.subplot(1, 3, 3)\n        plt.plot(epochs, history['train_acc5'], label='Train ACC@5')\n        plt.plot(epochs, history['val_acc5'], label='Val ACC@5')\n        plt.xlabel('Epoch')\n        plt.ylabel('Accuracy')\n        plt.title('Train vs Val ACC@5')\n        plt.legend()\n\n        plt.tight_layout()\n        plt.show()\n\n\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    correct_top1 = 0\n    correct_top5 = 0\n    total = 0\n\n    start_time = time.time()\n\n    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n\n    for images, labels in progress_bar:\n        images, labels = images.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n        _, preds = outputs.topk(5, dim=1)\n        correct = preds.eq(labels.view(-1, 1))\n\n        correct_top1 += correct[:, 0].sum().item()\n        correct_top5 += correct.any(dim=1).sum().item()\n        total += labels.size(0)\n\n        acc1_batch = correct[:, 0].sum().item() / labels.size(0)\n        acc5_batch = correct.any(dim=1).sum().item() / labels.size(0)\n        progress_bar.set_postfix(loss=loss.item(), acc1=acc1_batch, acc5=acc5_batch)\n\n    train_time = time.time() - start_time\n    train_loss = running_loss / len(train_loader)\n    train_acc1 = correct_top1 / total\n    train_acc5 = correct_top5 / total\n\n    # Run validation\n    val_loss, val_acc1, val_acc5 = evaluate(model, val_loader, device)\n\n    # Store in history\n    history['train_loss'].append(train_loss)\n    history['train_acc1'].append(train_acc1)\n    history['train_acc5'].append(train_acc5)\n    history['val_loss'].append(val_loss)\n    history['val_acc1'].append(val_acc1)\n    history['val_acc5'].append(val_acc5)\n\n    print(f\"Epoch {epoch+1}/{num_epochs} | Time: {train_time:.1f}s\")\n    print(f\"  Train     | Loss: {train_loss:.4f} | ACC@1: {train_acc1:.4f} | ACC@5: {train_acc5:.4f}\")\n    print(f\"  Validation| Loss: {val_loss:.4f}   | ACC@1: {val_acc1:.4f}   | ACC@5: {val_acc5:.4f}\")\n    plot_history(history)\n\ntorch.save(model.state_dict(), 'vit_b_16_butterfly_classification.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:07:29.221140Z","iopub.execute_input":"2025-05-04T11:07:29.221413Z","iopub.status.idle":"2025-05-04T11:45:47.771879Z","shell.execute_reply.started":"2025-05-04T11:07:29.221392Z","shell.execute_reply":"2025-05-04T11:45:47.771125Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_v2 = torchvision.models.convnext_base(weights=torchvision.models.ConvNeXt_Base_Weights.DEFAULT)\nmodel_v2.classifier[2] = nn.Linear(model_v2.classifier[2].in_features, num_classes)\nmodel_v2 = model_v2.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:57:30.225110Z","iopub.execute_input":"2025-05-04T11:57:30.225411Z","iopub.status.idle":"2025-05-04T11:57:31.839705Z","shell.execute_reply.started":"2025-05-04T11:57:30.225391Z","shell.execute_reply":"2025-05-04T11:57:31.838945Z"},"_kg_hide-input":false},"outputs":[],"execution_count":19},{"cell_type":"code","source":"criterion_v2 = nn.CrossEntropyLoss()\noptimizer_v2 = optim.Adam(model_v2.parameters(), lr=1e-4)\n\nhistory_v2 = {\n    'train_loss': [],\n    'train_acc1': [],\n    'train_acc5': [],\n    'val_loss': [],\n    'val_acc1': [],\n    'val_acc5': []\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T12:13:55.367809Z","iopub.execute_input":"2025-05-04T12:13:55.368432Z","iopub.status.idle":"2025-05-04T12:13:55.373759Z","shell.execute_reply.started":"2025-05-04T12:13:55.368407Z","shell.execute_reply":"2025-05-04T12:13:55.373082Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"num_epochs_v2 = 10\n\nfor epoch in range(num_epochs_v2):\n    start_time = time.time()\n    \n    # Training\n    model_v2.train()\n    train_loss_v2 = 0.0\n    correct1_train_v2 = 0\n    correct5_train_v2 = 0\n    total_train_v2 = 0\n\n    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs_v2} [Train]\"):\n        images, labels = images.to(device), labels.to(device)\n\n        optimizer_v2.zero_grad()\n        outputs = model_v2(images)\n        loss = criterion_v2(outputs, labels)\n        loss.backward()\n        optimizer_v2.step()\n\n        train_loss_v2 += loss.item() * images.size(0)\n        total_train_v2 += labels.size(0)\n\n        _, preds = outputs.topk(5, dim=1, largest=True, sorted=True)\n        correct1_train_v2 += (preds[:, 0] == labels).sum().item()\n        correct5_train_v2 += sum([labels[i] in preds[i] for i in range(labels.size(0))])\n\n    train_loss_v2 /= total_train_v2\n    acc1_train_v2 = correct1_train_v2 / total_train_v2\n    acc5_train_v2 = correct5_train_v2 / total_train_v2\n\n    # Validation\n    model_v2.eval()\n    val_loss_v2 = 0.0\n    correct1_val_v2 = 0\n    correct5_val_v2 = 0\n    total_val_v2 = 0\n\n    with torch.no_grad():\n        for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs_v2} [Val]\"):\n            images, labels = images.to(device), labels.to(device)\n            outputs = model_v2(images)\n            loss = criterion_v2(outputs, labels)\n\n            val_loss_v2 += loss.item() * images.size(0)\n            total_val_v2 += labels.size(0)\n\n            _, preds = outputs.topk(5, dim=1, largest=True, sorted=True)\n            correct1_val_v2 += (preds[:, 0] == labels).sum().item()\n            correct5_val_v2 += sum([labels[i] in preds[i] for i in range(labels.size(0))])\n\n    val_loss_v2 /= total_val_v2\n    acc1_val_v2 = correct1_val_v2 / total_val_v2\n    acc5_val_v2 = correct5_val_v2 / total_val_v2\n\n    # Time\n    epoch_time = time.time() - start_time\n\n    # Logging\n    print(f\"Epoch {epoch+1}/{num_epochs_v2} | Time: {epoch_time:.1f}s\")\n    print(f\"  Train     | Loss: {train_loss_v2:.4f} | ACC@1: {acc1_train_v2:.4f} | ACC@5: {acc5_train_v2:.4f}\")\n    print(f\"  Validation| Loss: {val_loss_v2:.4f}   | ACC@1: {acc1_val_v2:.4f}   | ACC@5: {acc5_val_v2:.4f}\")\n\n    # History update\n    history_v2['train_loss'].append(train_loss_v2)\n    history_v2['train_acc1'].append(acc1_train_v2)\n    history_v2['train_acc5'].append(acc5_train_v2)\n    history_v2['val_loss'].append(val_loss_v2)\n    history_v2['val_acc1'].append(acc1_val_v2)\n    history_v2['val_acc5'].append(acc5_val_v2)\n\n    # Plot (uses original `plot_history()` but can be duplicated to `plot_history_v2` if needed)\n    plot_history(history_v2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T12:13:57.617590Z","iopub.execute_input":"2025-05-04T12:13:57.618137Z","iopub.status.idle":"2025-05-04T12:33:02.053584Z","shell.execute_reply.started":"2025-05-04T12:13:57.618111Z","shell.execute_reply":"2025-05-04T12:33:02.052274Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/10 [Train]: 100%|██████████| 163/163 [03:55<00:00,  1.45s/it]\nEpoch 1/10 [Val]: 100%|██████████| 41/41 [00:18<00:00,  2.21it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10 | Time: 254.2s\n  Train     | Loss: 2.3661 | ACC@1: 0.6024 | ACC@5: 0.7884\n  Validation| Loss: 0.6507   | ACC@1: 0.8815   | ACC@5: 0.9854\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 2/10 [Train]: 100%|██████████| 163/163 [03:51<00:00,  1.42s/it]\nEpoch 2/10 [Val]: 100%|██████████| 41/41 [00:18<00:00,  2.22it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 2/10 | Time: 250.2s\n  Train     | Loss: 0.4279 | ACC@1: 0.9327 | ACC@5: 0.9940\n  Validation| Loss: 0.3011   | ACC@1: 0.9315   | ACC@5: 0.9915\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 3/10 [Train]: 100%|██████████| 163/163 [03:53<00:00,  1.44s/it]\nEpoch 3/10 [Val]: 100%|██████████| 41/41 [00:18<00:00,  2.25it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 3/10 | Time: 252.2s\n  Train     | Loss: 0.1678 | ACC@1: 0.9711 | ACC@5: 0.9987\n  Validation| Loss: 0.2404   | ACC@1: 0.9408   | ACC@5: 0.9931\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 4/10 [Train]: 100%|██████████| 163/163 [03:56<00:00,  1.45s/it]\nEpoch 4/10 [Val]: 100%|██████████| 41/41 [00:18<00:00,  2.27it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 4/10 | Time: 254.9s\n  Train     | Loss: 0.0815 | ACC@1: 0.9871 | ACC@5: 0.9998\n  Validation| Loss: 0.2411   | ACC@1: 0.9369   | ACC@5: 0.9923\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 5/10 [Train]:  55%|█████▌    | 90/163 [02:10<01:46,  1.45s/it]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/1075378895.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":22},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}